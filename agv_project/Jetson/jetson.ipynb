{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "familiar-salvation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Cell 1 Loaded\n"
     ]
    }
   ],
   "source": [
    "import time, json, math, threading\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import paho.mqtt.client as mqtt\n",
    "from jetbot import Robot, Camera\n",
    "\n",
    "import Adafruit_SSD1306\n",
    "import os, time\n",
    "import json\n",
    "import subprocess\n",
    "from jetbot.utils.utils import get_ip_address\n",
    "from jetbot import ina219 \n",
    "from jetbot import ads1115\n",
    "\n",
    "# ===== MQTT ÏÑ§Ï†ï (Í∏∞Ï°¥ IP Ïú†ÏßÄ) =====\n",
    "BROKER_IP    = \"10.41.145.221\"\n",
    "BROKER_PORT  = 1883\n",
    "TOPIC_TASK   = \"robot/agv1/task\"\n",
    "TOPIC_STATUS = \"robot/agv1/status\"\n",
    "\n",
    "CLIENT_ID = f\"jetbot-agv1-step3-{int(time.time()*1000)}\"\n",
    "robot_id = \"agv1\"\n",
    "\n",
    "# ===== ÌååÏùº Í≤ΩÎ°ú =====\n",
    "MODEL_PATH = Path(\"pjt/models/best_steering_model_xy_test.pth\")\n",
    "TRACK_PATH = Path(\"track_agv1.json\")\n",
    "\n",
    "# ===== ÌÉÄÏù¥Î∞ç ÏÑ§Ï†ï =====\n",
    "STATUS_PERIOD_SEC = 0.5\n",
    "LINE_LOOP_DT = 0.02\n",
    "\n",
    "# ===== ÎùºÏù∏ Ìä∏Î†àÏù¥Ïã± ÌååÎùºÎØ∏ÌÑ∞ =====\n",
    "SPEED = 0.30\n",
    "STEERING_GAIN  = 0.20\n",
    "STEERING_DGAIN = 0.05\n",
    "STEERING_BIAS  = 0.00\n",
    "\n",
    "LOG_EVERY_SEC = 1.0\n",
    "PRINT_MOTOR   = True\n",
    "\n",
    "# ===== ÎîîÏßÄÌÑ∏ Ìä∏Ïúà Îû©ÌÉÄÏûÑ (Î≥¥Ï†ïÏö©) =====\n",
    "LAP_TIME_SEC = 56.22\n",
    "\n",
    "# ===== UserApp Í∏∞Ï§Ä Ï¢åÌëú (Î≥ÄÍ≤Ω ÏóÜÏùå) =====\n",
    "AREA_POS_UI = {\n",
    "    \"CHARGE\": {\"x\": 50, \"y\": 10},\n",
    "    \"WATER\":  {\"x\": 18, \"y\": 28},\n",
    "    \"DROP\":   {\"x\": 82, \"y\": 42},\n",
    "    \"RES_A\":  {\"x\": 20, \"y\": 70},\n",
    "    \"RES_B\":  {\"x\": 42, \"y\": 82},\n",
    "    \"RES_C\":  {\"x\": 70, \"y\": 82},\n",
    "}\n",
    "\n",
    "print(\"[OK] Cell 1 Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interested-fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OD] Loading model from: models/best-fp16.tflite\n",
      "[OD] Model Loaded Successfully ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# ===== [Step 4] Í∞ùÏ≤¥ Ïù∏Ïãù(OD) Î™®Îç∏ Î°úÎî© =====\n",
    "from tflite_runtime.interpreter import Interpreter\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# ÌåÄÏõê ÏΩîÎìú Í≤ΩÎ°ú: models/best-fp16.tflite\n",
    "# Step3 Í≤ΩÎ°ú Í∏∞Ï§Ä: pjt/models/best-fp16.tflite ÎùºÍ≥† Í∞ÄÏ†ï (Ïïà ÎêòÎ©¥ Í≤ΩÎ°ú ÏàòÏ†ï ÌïÑÏöî)\n",
    "OD_MODEL_PATH = Path(\"pjt/models/best-fp16.tflite\") \n",
    "\n",
    "# Í≤ΩÎ°ú ÏïàÏ†Ñ Ïû•Ïπò\n",
    "if not OD_MODEL_PATH.exists():\n",
    "    # ÌòπÏãú Î™∞Îùº ÌòÑÏû¨ Í≤ΩÎ°ú Í∏∞Ï§ÄÎèÑ Ï≤¥ÌÅ¨\n",
    "    OD_MODEL_PATH = Path(\"models/best-fp16.tflite\")\n",
    "\n",
    "print(f\"[OD] Loading model from: {OD_MODEL_PATH}\")\n",
    "\n",
    "try:\n",
    "    od_interpreter = Interpreter(model_path=str(OD_MODEL_PATH))\n",
    "    od_interpreter.allocate_tensors()\n",
    "    od_input_details = od_interpreter.get_input_details()\n",
    "    od_output_details = od_interpreter.get_output_details()\n",
    "    \n",
    "    OD_LABELS = ['block', 'cup', 'doll'] # ÌåÄÏõê ÏΩîÎìú Í∏∞Ï§Ä ÎùºÎ≤®\n",
    "    \n",
    "    print(\"[OD] Model Loaded Successfully ‚úÖ\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"[OD] ‚ùå Model Load Error: {e}\")\n",
    "    od_interpreter = None\n",
    "\n",
    "# ÌåÄÏõê ÏΩîÎìúÏùò get_usb_detsÎ•º Í∞ÄÏ†∏ÏôÄÏÑú JetBot Ïπ¥Î©îÎùº Ìè¨Îß∑(frame)Ïóê ÎßûÍ≤å ÏàòÏ†ï\n",
    "def detect_objects(frame):\n",
    "    if od_interpreter is None or frame is None:\n",
    "        return []\n",
    "        \n",
    "    h, w = frame.shape[:2]\n",
    "    # ÏûÖÎ†• Ï†ÑÏ≤òÎ¶¨: 224x224 Î¶¨ÏÇ¨Ïù¥Ï¶à -> RGB Î≥ÄÌôò -> Normalize\n",
    "    img = cv2.resize(frame, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "    \n",
    "    # Ï∂îÎ°† Ïã§Ìñâ\n",
    "    od_interpreter.set_tensor(od_input_details[0]['index'], np.expand_dims(img, axis=0))\n",
    "    od_interpreter.invoke()\n",
    "    output = od_interpreter.get_tensor(od_output_details[0]['index'])\n",
    "    \n",
    "    # ÌõÑÏ≤òÎ¶¨ (NMS)\n",
    "    boxes, scores, classes = [], [], []\n",
    "    for row in output[0]:\n",
    "        if row[4] > 0.5: # Confidence Threshold (ÌåÄÏõê ÏΩîÎìúÎäî 0.6Ïù¥ÏóàÏúºÎÇò 0.5Î°ú ÏÇ¥Ïßù ÏôÑÌôî)\n",
    "            cls_id = np.argmax(row[5:])\n",
    "            cx, cy, bw, bh = row[:4]\n",
    "            boxes.append([int((cx-bw/2)*w), int((cy-bh/2)*h), int((cx+bw/2)*w), int((cy+bh/2)*h)])\n",
    "            scores.append(float(row[4] * row[5+cls_id]))\n",
    "            classes.append(int(cls_id))\n",
    "    \n",
    "    # NMS Ï†ÅÏö©\n",
    "    if len(boxes) > 0:\n",
    "        idxs = cv2.dnn.NMSBoxes(boxes, scores, 0.35, 0.45)\n",
    "        if len(idxs) > 0:\n",
    "            results = []\n",
    "            for i in idxs.flatten():\n",
    "                lbl = OD_LABELS[classes[i]]\n",
    "                results.append((lbl, scores[i], boxes[i]))\n",
    "            return results\n",
    "            \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "official-american",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRACK] N = 800\n",
      "[TRACK] START_IDX = 794\n",
      "[AREA_TO_IDX]\n",
      " CHARGE -> 794\n",
      " WATER -> 134\n",
      " DROP -> 615\n",
      " RES_A -> 259\n",
      " RES_B -> 367\n",
      " RES_C -> 452\n"
     ]
    }
   ],
   "source": [
    "def load_track_points(path: Path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"track json not found: {path.resolve()}\")\n",
    "\n",
    "    obj = json.loads(path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    if isinstance(obj, dict) and isinstance(obj.get(\"dense\"), list):\n",
    "        pts = obj[\"dense\"]\n",
    "    elif isinstance(obj, list):\n",
    "        pts = obj\n",
    "    else:\n",
    "        raise ValueError(\"Unknown track json format\")\n",
    "\n",
    "    out = []\n",
    "    for p in pts:\n",
    "        if not isinstance(p, dict): continue\n",
    "        x, y = p.get(\"x\"), p.get(\"y\")\n",
    "        if x is None or y is None: continue\n",
    "        if not np.isfinite(x) or not np.isfinite(y): continue\n",
    "        out.append({\"x\": float(x), \"y\": float(y)})\n",
    "\n",
    "    # Ìä∏Îûô Îã´Ìûò Ï≤òÎ¶¨ (ÏãúÏûëÏ†ê==ÎÅùÏ†êÏù¥Î©¥ Ï§ëÎ≥µ Ï†úÍ±∞)\n",
    "    if len(out) >= 2:\n",
    "        dx = out[0][\"x\"] - out[-1][\"x\"]\n",
    "        dy = out[0][\"y\"] - out[-1][\"y\"]\n",
    "        if dx*dx + dy*dy < 1e-9:\n",
    "            out = out[:-1]\n",
    "\n",
    "    if len(out) < 2:\n",
    "        raise ValueError(\"track points too short\")\n",
    "\n",
    "    return out\n",
    "\n",
    "TRACK_POINTS = load_track_points(TRACK_PATH)\n",
    "TRACK_N = len(TRACK_POINTS)\n",
    "POINTS_PER_SEC = TRACK_N / max(LAP_TIME_SEC, 1e-6)\n",
    "\n",
    "def nearest_track_idx(x, y):\n",
    "    best_i, best_d = 0, 1e18\n",
    "    for i, p in enumerate(TRACK_POINTS):\n",
    "        dx = p[\"x\"] - x\n",
    "        dy = p[\"y\"] - y\n",
    "        d = dx*dx + dy*dy\n",
    "        if d < best_d:\n",
    "            best_d, best_i = d, i\n",
    "    return best_i\n",
    "\n",
    "TRACK_START_IDX = nearest_track_idx(AREA_POS_UI[\"CHARGE\"][\"x\"], AREA_POS_UI[\"CHARGE\"][\"y\"])\n",
    "\n",
    "print(\"[TRACK] N =\", TRACK_N)\n",
    "print(\"[TRACK] START_IDX =\", TRACK_START_IDX)\n",
    "\n",
    "# AREA Ï¢åÌëú -> Ìä∏Îûô Ïù∏Îç±Ïä§ Îß§Ìïë\n",
    "AREA_TO_IDX = {k: nearest_track_idx(v[\"x\"], v[\"y\"]) for k, v in AREA_POS_UI.items()}\n",
    "\n",
    "print(\"[AREA_TO_IDX]\")\n",
    "for k in AREA_TO_IDX:\n",
    "    print(f\" {k} -> {AREA_TO_IDX[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "right-gnome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CWD] /workspace/pjt\n",
      "[OK] MODEL_PATH = /workspace/pjt/models/best_steering_model_xy_test.pth\n",
      "[OK] TRACK_PATH = /workspace/pjt/track_agv1.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def resolve_path(p: Path) -> Path:\n",
    "    if p.exists():\n",
    "        return p.resolve()\n",
    "    # Í≤ΩÎ°ú Î™ª Ï∞æÏùÑ Ïãú ÌõÑÎ≥¥Íµ∞ ÌÉêÏÉâ\n",
    "    candidates = [\n",
    "        Path.cwd() / p,\n",
    "        Path.cwd() / \"pjt\" / \"models\" / p.name,\n",
    "        Path.cwd().parent / \"pjt\" / \"models\" / p.name,\n",
    "        Path(\"/home/jetbot/Notebooks\") / p,\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c.exists(): return c.resolve()\n",
    "    \n",
    "    # ÏµúÌõÑÏùò ÏàòÎã®: Ï†ÑÏ≤¥ Í≤ÄÏÉâ\n",
    "    matches = list(Path.cwd().rglob(p.name))\n",
    "    if matches: return matches[0].resolve()\n",
    "    \n",
    "    raise FileNotFoundError(f\"NOT FOUND: {p}\")\n",
    "\n",
    "print(\"[CWD]\", Path.cwd())\n",
    "\n",
    "MODEL_PATH = resolve_path(MODEL_PATH)\n",
    "TRACK_PATH = resolve_path(TRACK_PATH)\n",
    "\n",
    "print(\"[OK] MODEL_PATH =\", MODEL_PATH)\n",
    "print(\"[OK] TRACK_PATH =\", TRACK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hindu-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] model loaded | device=cuda fp16=True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "use_fp16 = (device.type == \"cuda\")\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "\n",
    "state_dict = torch.load(str(MODEL_PATH), map_location=\"cpu\")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model = model.to(device).eval()\n",
    "if use_fp16:\n",
    "    model = model.half()\n",
    "\n",
    "mean = torch.tensor([0.485, 0.456, 0.406], device=device)\n",
    "std  = torch.tensor([0.229, 0.224, 0.225], device=device)\n",
    "if use_fp16:\n",
    "    mean = mean.half()\n",
    "    std  = std.half()\n",
    "\n",
    "def preprocess(frame_bgr_or_rgb):\n",
    "    img = PIL.Image.fromarray(frame_bgr_or_rgb)\n",
    "    t = transforms.functional.to_tensor(img).to(device)\n",
    "    if use_fp16:\n",
    "        t = t.half()\n",
    "    t.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return t[None, ...]\n",
    "\n",
    "print(f\"[OK] model loaded | device={device} fp16={use_fp16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "checked-microphone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Robot & Camera ready\n",
      "[OK] motors primed\n",
      "[OK] model warmup done\n",
      "[OK] INA219 Battery Sensor Connected\n"
     ]
    }
   ],
   "source": [
    "try: robot.stop()\n",
    "except: pass\n",
    "\n",
    "robot = Robot()\n",
    "robot.stop()\n",
    "camera = Camera()\n",
    "\n",
    "print(\"[OK] Robot & Camera ready\")\n",
    "\n",
    "def prime_motors(val=0.15, duration=0.25):\n",
    "    robot.left_motor.value  = val\n",
    "    robot.right_motor.value = val\n",
    "    time.sleep(duration)\n",
    "    robot.stop()\n",
    "    time.sleep(0.15)\n",
    "\n",
    "prime_motors()\n",
    "print(\"[OK] motors primed\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def warmup_model(n=20):\n",
    "    for _ in range(n):\n",
    "        f = camera.value\n",
    "        if f is None:\n",
    "            time.sleep(0.05); continue\n",
    "        _ = model(preprocess(f))\n",
    "        time.sleep(0.02)\n",
    "\n",
    "warmup_model(20)\n",
    "print(\"[OK] model warmup done\")\n",
    "\n",
    "# ===== [Ï∂îÍ∞Ä] Î∞∞ÌÑ∞Î¶¨ ÏÑºÏÑú (INA219) Ï¥àÍ∏∞Ìôî =====\n",
    "ina = None\n",
    "try:\n",
    "    ina = ina219.INA219(addr=0x41)\n",
    "    print(\"[OK] INA219 Battery Sensor Connected\")\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] INA219 sensor not found: {e}\")\n",
    "    ina = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "average-nashville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Shared State & Waypoints Ready\n"
     ]
    }
   ],
   "source": [
    "# ----- Shared State -----\n",
    "state_lock = threading.Lock()\n",
    "\n",
    "state = \"idle\"            # idle / running / working / error / done\n",
    "current_task_id = None\n",
    "area = \"CHARGE\"\n",
    "target_area = None\n",
    "error_code = None\n",
    "battery = 66\n",
    "\n",
    "# ----- Step3 ÌïµÏã¨: Waypoints Queue -----\n",
    "current_waypoints = []   # Ïòà: [\"WATER\", \"RES_A\", \"CHARGE\"]\n",
    "target_idx = None        # ÌòÑÏû¨ Î™©Ï†ÅÏßÄ Ïù∏Îç±Ïä§\n",
    "track_dir = +1           # +1 Ï†ïÎ∞©Ìñ•, -1 Ïó≠Î∞©Ìñ•\n",
    "\n",
    "# ----- Timeouts -----\n",
    "done_until = 0.0\n",
    "ARRIVE_IDX_TOL = 4\n",
    "ARRIVE_HOLD_SEC = 0.4\n",
    "DONE_HOLD_SEC = 1.0\n",
    "WORKING_SEC = 2.0        # ÎèÑÏ∞© ÌõÑ Í∞ÄÏßú ÏûëÏóÖ ÏãúÍ∞Ñ (2Ï¥à)\n",
    "\n",
    "# ----- Track Progress (Digital Twin) -----\n",
    "track_lock = threading.Lock()\n",
    "track_idx_f = float(TRACK_START_IDX)\n",
    "track_last_t = time.monotonic()\n",
    "\n",
    "def reset_track_to_start():\n",
    "    global track_idx_f, track_last_t\n",
    "    with track_lock:\n",
    "        track_idx_f = float(TRACK_START_IDX)\n",
    "        track_last_t = time.monotonic()\n",
    "\n",
    "def update_track_progress_if_running(is_running: bool, did_drive: bool):\n",
    "    global track_idx_f, track_last_t, track_dir\n",
    "    now = time.monotonic()\n",
    "    with track_lock:\n",
    "        dt = now - track_last_t\n",
    "        track_last_t = now\n",
    "        if dt < 0 or dt > 0.2: return\n",
    "        \n",
    "        # Ïã§Ï†úÎ°ú Î™®ÌÑ∞Í∞Ä Îèå ÎïåÎßå Ìä∏Îûô Ïù∏Îç±Ïä§ Ïù¥Îèô\n",
    "        if not (is_running and did_drive):\n",
    "            return\n",
    "\n",
    "        track_idx_f = (track_idx_f + dt * POINTS_PER_SEC * track_dir) % TRACK_N\n",
    "\n",
    "def get_track_pose():\n",
    "    with track_lock:\n",
    "        idx = int(track_idx_f) % TRACK_N\n",
    "    step = 1 if track_dir >= 0 else -1\n",
    "    p = TRACK_POINTS[idx]\n",
    "    p2 = TRACK_POINTS[(idx + step) % TRACK_N]\n",
    "    theta = math.atan2(p2[\"y\"] - p[\"y\"], p2[\"x\"] - p[\"x\"])\n",
    "    return {\"x\": float(p[\"x\"]), \"y\": float(p[\"y\"]), \"theta\": float(theta)}, {\"track_idx\": idx, \"dir\": track_dir}\n",
    "\n",
    "def choose_shortest_dir(cur_idx: int, tgt_idx: int) -> int:\n",
    "    fwd = (tgt_idx - cur_idx) % TRACK_N\n",
    "    bwd = (cur_idx - tgt_idx) % TRACK_N\n",
    "    return +1 if fwd <= bwd else -1\n",
    "\n",
    "def ring_dist(a: int, b: int) -> int:\n",
    "    d1 = (b - a) % TRACK_N\n",
    "    d2 = (a - b) % TRACK_N\n",
    "    return min(d1, d2)\n",
    "\n",
    "print(\"[OK] Shared State & Waypoints Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-marshall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n",
      "[LOOP] Step 4 Final (Resource Optimized).[OK] Step4 Final RESTARTED (Resource Optimized)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== [Step 4 Final: Resource Optimization] USB Ïπ¥Î©îÎùº On-Demand Î∞©Ïãù =====\n",
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from SCSCtrl import TTLServo\n",
    "from tflite_runtime.interpreter import Interpreter\n",
    "\n",
    "# =========================================================\n",
    "# 0. Ìó¨Ìçº Ìï®Ïàò & ÏïàÏ†ÑÏû•Ïπò\n",
    "# =========================================================\n",
    "if 'track_lock' not in globals():\n",
    "    track_lock = threading.Lock()\n",
    "    track_idx_f = 0.0\n",
    "    track_last_t = time.monotonic()\n",
    "    track_dir = 1\n",
    "\n",
    "def update_track_progress_if_running(is_running: bool, did_drive: bool):\n",
    "    global track_idx_f, track_last_t, track_dir\n",
    "    _PPS = globals().get('POINTS_PER_SEC', 10.0) \n",
    "    _TN = globals().get('TRACK_N', 800)\n",
    "    now = time.monotonic()\n",
    "    with track_lock:\n",
    "        dt = now - track_last_t\n",
    "        track_last_t = now\n",
    "        if dt < 0 or dt > 0.2: return\n",
    "        if not (is_running and did_drive): return\n",
    "        track_idx_f = (track_idx_f + dt * _PPS * track_dir) % _TN\n",
    "\n",
    "def choose_shortest_dir(cur_idx: int, tgt_idx: int) -> int:\n",
    "    _TN = globals().get('TRACK_N', 800)\n",
    "    fwd = (tgt_idx - cur_idx) % _TN\n",
    "    bwd = (cur_idx - tgt_idx) % _TN\n",
    "    return +1 if fwd <= bwd else -1\n",
    "\n",
    "def ring_dist(a: int, b: int) -> int:\n",
    "    _TN = globals().get('TRACK_N', 800)\n",
    "    d1 = (b - a) % _TN\n",
    "    d2 = (a - b) % _TN\n",
    "    return min(d1, d2)\n",
    "\n",
    "def snap_track_idx(idx: int):\n",
    "    global track_idx_f, track_last_t\n",
    "    with track_lock:\n",
    "        track_idx_f = float(idx)\n",
    "        track_last_t = time.monotonic()\n",
    "\n",
    "# ‚òÖ Í∞ùÏ≤¥ Ïù∏Ïãù Ìï®Ïàò (ÎùºÎ≤® ÌïòÎìúÏΩîÎî©)\n",
    "def detect_objects_debug(frame):\n",
    "    if 'od_interpreter' not in globals() or od_interpreter is None:\n",
    "        return []\n",
    "    if frame is None: return []\n",
    "\n",
    "    MY_LABELS = ['block', 'cup', 'doll']\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    img = cv2.resize(frame, (224, 224))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "    od_interpreter.set_tensor(od_input_details[0]['index'], np.expand_dims(img, axis=0))\n",
    "    od_interpreter.invoke()\n",
    "    output = od_interpreter.get_tensor(od_output_details[0]['index'])\n",
    "\n",
    "    boxes, scores, classes = [], [], []\n",
    "    for row in output[0]:\n",
    "        score = float(row[4])\n",
    "        if score > 0.4:  \n",
    "            cls_id = int(np.argmax(row[5:]))\n",
    "            cx, cy, bw, bh = row[:4]\n",
    "            boxes.append([int((cx-bw/2)*w), int((cy-bh/2)*h), int((cx+bw/2)*w), int((cy+bh/2)*h)])\n",
    "            scores.append(float(score * row[5+cls_id]))\n",
    "            if cls_id < len(MY_LABELS): classes.append(MY_LABELS[cls_id])\n",
    "            else: classes.append(str(cls_id))\n",
    "\n",
    "    if len(boxes) > 0:\n",
    "        idxs = cv2.dnn.NMSBoxes(boxes, scores, 0.35, 0.45)\n",
    "        if len(idxs) > 0:\n",
    "            results = []\n",
    "            for i in idxs.flatten():\n",
    "                results.append((classes[i], scores[i], boxes[i]))\n",
    "            return results\n",
    "    return []\n",
    "\n",
    "# =========================================================\n",
    "# 1. Ï†ÑÏó≠ Î≥ÄÏàò ÏÑ§Ï†ï\n",
    "# =========================================================\n",
    "line_stop = threading.Event()\n",
    "line_follow_enabled = False\n",
    "_lock = threading.Lock()\n",
    "\n",
    "_PRINT_MOTOR = globals().get('PRINT_MOTOR', True)\n",
    "_LOG_EVERY_SEC = globals().get('LOG_EVERY_SEC', 1.0)\n",
    "_last_log_t = 0.0\n",
    "\n",
    "_ARRIVE_IDX_TOL = globals().get('ARRIVE_IDX_TOL', 4)\n",
    "_ARRIVE_HOLD_SEC = globals().get('ARRIVE_HOLD_SEC', 0.4)\n",
    "_DONE_HOLD_SEC = globals().get('DONE_HOLD_SEC', 1.0) # Done Ïú†ÏßÄ ÏãúÍ∞Ñ\n",
    "\n",
    "force_arrival = False \n",
    "current_task_type = \"unknown\"\n",
    "angle_last = 0.0\n",
    "STOP_LINE_Y_CUP = 110 \n",
    "CENTER_Y = 112 \n",
    "\n",
    "# =========================================================\n",
    "# 2. ÌïòÎìúÏõ®Ïñ¥ ÌÅ¥ÎûòÏä§ (On-Demand Camera)\n",
    "# =========================================================\n",
    "class AgvHardware:\n",
    "    def __init__(self):\n",
    "        self.pan_angle = 5\n",
    "        self.servo1_speed = 0.05\n",
    "        self.forward_speed = 0.13\n",
    "        \n",
    "        # Ï¢åÌëúÍ∞í\n",
    "        self.CUP_APPROACH = (130, -140)\n",
    "        self.CUP_GRAB     = (180, -125)\n",
    "        self.CUP_LIFT     = (180, -100)\n",
    "        self.CUP_PLACE    = (180, -130)\n",
    "        self.DOLL_APPROACH = (150, -140)\n",
    "        self.DOLL_GRAB     = (150, -140)\n",
    "        self.DOLL_LIFT     = (150, 80)\n",
    "        self.DOLL_PLACE    = (150, -110)\n",
    "        \n",
    "        # Ï¥àÍ∏∞Ìôî ÏãúÏóî Ïπ¥Î©îÎùºÎäî Ïïà Í≤Ä. ÏÑúÎ≥¥Îßå Î¶¨ÏÖã.\n",
    "        self.reset_servos()\n",
    "\n",
    "    # ‚òÖ [ÌïµÏã¨] ÌïÑÏöîÌï† ÎïåÎßå Ïó¥Í≥† Îã´Îäî Ìï®Ïàò\n",
    "    def open_usb_camera(self):\n",
    "        print(\"[HW] Opening USB Camera...\")\n",
    "        cap = cv2.VideoCapture(1)\n",
    "        if not cap.isOpened():\n",
    "            print(\"[HW] ‚ö†Ô∏è Video(1) failed. Trying Video(0)...\")\n",
    "            cap = cv2.VideoCapture(0)\n",
    "        return cap\n",
    "\n",
    "    def reset_servos(self):\n",
    "        try:\n",
    "            TTLServo.servoAngleCtrl(4, 5, 1, 150)\n",
    "            TTLServo.servoAngleCtrl(5, 50, 1, 100) # Ï£ºÌñâ Í∞ÅÎèÑ\n",
    "            TTLServo.servoAngleCtrl(3, 20, 1, 150)\n",
    "            time.sleep(0.5)\n",
    "            TTLServo.xyInput(100, 100)\n",
    "            time.sleep(0.5)\n",
    "            TTLServo.servoAngleCtrl(1, 5, 1, 100)\n",
    "            self.pan_angle = 5\n",
    "        except: pass\n",
    "\n",
    "    # --- Motions ---\n",
    "    def _pick_cup_motion(self):\n",
    "        print(\"ü¶æ [HW] Picking Cup...\")\n",
    "        TTLServo.servoAngleCtrl(4, 10, 1, 150) \n",
    "        TTLServo.xyInputSmooth(130, -140, 3.0); time.sleep(4.0) \n",
    "        TTLServo.xyInputSmooth(180, -125, 3.0); time.sleep(3.0) \n",
    "        TTLServo.servoAngleCtrl(4, -25, 1, 150); time.sleep(2.0) \n",
    "        TTLServo.xyInputSmooth(180, -100, 3.0); time.sleep(3.0) \n",
    "\n",
    "    def _place_cup_motion(self):\n",
    "        print(\"ü¶æ [HW] Placing Cup...\")\n",
    "        TTLServo.xyInputSmooth(180, -130, 3.0); time.sleep(3.0)\n",
    "        TTLServo.servoAngleCtrl(4, 10, 1, 150); time.sleep(2.0)\n",
    "        self.reset_servos()\n",
    "\n",
    "    def _pick_doll(self):\n",
    "        print(\"ü¶æ [HW] Action: Picking Doll\")\n",
    "        TTLServo.servoAngleCtrl(4, 10, 1, 150) \n",
    "        TTLServo.xyInput(150, -140); time.sleep(2.0)\n",
    "        TTLServo.servoAngleCtrl(4, -80, 1, 150); time.sleep(2.0)\n",
    "        TTLServo.xyInput(150, 80); time.sleep(3.0)\n",
    "    \n",
    "    def _place_doll(self):\n",
    "        print(\"ü¶æ [HW] Action: Placing Doll\")\n",
    "        TTLServo.xyInput(150, -110); time.sleep(1.0)\n",
    "        TTLServo.servoAngleCtrl(4, 10, 1, 150); time.sleep(2.0)\n",
    "\n",
    "    def _pick_block(self):\n",
    "        print(\"ü¶æ [HW] Action: Picking Block\")\n",
    "        TTLServo.servoAngleCtrl(4, 10, 1, 150) \n",
    "        TTLServo.xyInputSmooth(150, -125, 2.0); time.sleep(2.0)\n",
    "        TTLServo.servoAngleCtrl(4, -30, 1, 150); time.sleep(0.5)\n",
    "        TTLServo.xyInput(150, 80); time.sleep(3.0)\n",
    "\n",
    "    def _place_block(self):\n",
    "        print(\"ü¶æ [HW] Action: Placing Block\")\n",
    "        TTLServo.xyInput(150, -120); time.sleep(1.0)\n",
    "        TTLServo.servoAngleCtrl(3, -5, 1, 150); time.sleep(0.5)\n",
    "        TTLServo.servoAngleCtrl(4, 10, 1, 150); time.sleep(2.0)\n",
    "\n",
    "    # --- Align & Pick (Ïπ¥Î©îÎùº Ïó¥Í≥† -> ÏûëÏóÖ -> Îã´Í≥†) ---\n",
    "    def align_and_pick(self, target_label):\n",
    "        # 1. Ïπ¥Î©îÎùº Ïó¥Í∏∞\n",
    "        cap = self.open_usb_camera()\n",
    "        if not cap.isOpened():\n",
    "            print(\"[HW] ‚ùå Camera Open Failed. Skip job.\")\n",
    "            return\n",
    "\n",
    "        print(f\"üëÄ [ALIGN] Searching for '{target_label}'...\")\n",
    "        TTLServo.servoAngleCtrl(5, 50, 1, 100) \n",
    "        time.sleep(1.0)\n",
    "        \n",
    "        t_start = time.time()\n",
    "        step = 1 \n",
    "        last_seen_time = time.time()\n",
    "        final_label = \"unknown\"\n",
    "        \n",
    "        try:\n",
    "            while time.time() - last_seen_time < 15.0:\n",
    "                robot.stop()\n",
    "                time.sleep(0.1) \n",
    "                \n",
    "                ret, frame = cap.read()\n",
    "                if not ret: \n",
    "                    print(\"!\", end=\"\", flush=True); time.sleep(0.1); continue\n",
    "                \n",
    "                h, w = frame.shape[:2]\n",
    "                real_center_x = w // 2\n",
    "                if target_label == 'cup': real_stop_y = int(h * 0.23) \n",
    "                else: real_stop_y = h // 2\n",
    "\n",
    "                dets = detect_objects_debug(frame)\n",
    "                target_det = None\n",
    "\n",
    "                if target_request == 'laundry':\n",
    "                    # laundryÎäî 'doll' ÎòêÎäî 'block' Ï§ë Î®ºÏ†Ä Î∞úÍ≤¨Îêú Í≤ÉÏùÑ ÌÉÄÍ≤üÏúºÎ°ú Ìï®\n",
    "                    for d in dets:\n",
    "                        if 'doll' in d[0] or 'block' in d[0]:\n",
    "                            target_det = d; break\n",
    "                else: # 'cup' Îì± Îã®Ïùº ÌÉÄÍ≤ü\n",
    "                    for d in dets:\n",
    "                        if target_request in d[0]:\n",
    "                            target_det = d; break\n",
    "                \n",
    "                if not target_det:\n",
    "                    print(\".\", end=\"\", flush=True) \n",
    "                    continue\n",
    "                \n",
    "                last_seen_time = time.time()\n",
    "                print(f\" FOUND! {target_det}\")\n",
    "                (label, score, box) = target_det\n",
    "                final_label = label\n",
    "                x1, y1, x2, y2 = box\n",
    "                cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "                \n",
    "                if step == 1:\n",
    "                    target_y = real_stop_y\n",
    "                    offset_y = cy - target_y\n",
    "                    if abs(offset_y) > 5: \n",
    "                        speed = self.forward_speed if offset_y < 0 else -self.forward_speed\n",
    "                        robot.left_motor.value = speed; robot.right_motor.value = speed\n",
    "                        time.sleep(0.15); robot.stop()\n",
    "                    else:\n",
    "                        robot.stop()\n",
    "                        if 'cup' in label:\n",
    "                             robot.left_motor.value = -0.13; robot.right_motor.value = -0.13\n",
    "                             time.sleep(0.2); robot.stop()\n",
    "                        step = 2\n",
    "                        print(f\"\\n‚úÖ [ALIGN] Y-Align Done.\")\n",
    "                        time.sleep(0.5)\n",
    "                elif step == 2:\n",
    "                    offset_x = cx - real_center_x\n",
    "                    if abs(offset_x) > 5:\n",
    "                        self.pan_angle += offset_x * self.servo1_speed\n",
    "                        self.pan_angle = np.clip(self.pan_angle, -80, 80)\n",
    "                        TTLServo.servoAngleCtrl(1, int(self.pan_angle), 1, 150)\n",
    "                        time.sleep(0.2) \n",
    "                    else:\n",
    "                        print(f\"üéØ [ALIGN] X-Align Done. PICKING!\")\n",
    "                        robot.stop()\n",
    "                        time.sleep(0.5)\n",
    "                        \n",
    "                        # Ïπ¥Î©îÎùº ÎÅÑÍ≥† ÏßëÍ∏∞\n",
    "                        cap.release()\n",
    "\n",
    "                        # [ÏµúÏ¢Ö ÎèôÏûë Î∂ÑÍ∏∞]\n",
    "                        if 'cup' in final_label:\n",
    "                            self._pick_cup_motion()\n",
    "                        elif 'doll' in final_label:\n",
    "                            self._pick_doll()\n",
    "                        elif 'block' in final_label:\n",
    "                            self._pick_block()\n",
    "                        return\n",
    "                        \n",
    "            print(\"\\n‚ö†Ô∏è [ALIGN] Timeout.\")\n",
    "            \n",
    "        finally:\n",
    "            # ÏûëÏóÖ ÎÅùÎÇòÍ±∞ÎÇò ÏóêÎü¨ÎÇòÎ©¥ Î¨¥Ï°∞Í±¥ Ïπ¥Î©îÎùº Îã´Í∏∞\n",
    "            if cap.isOpened(): cap.release()\n",
    "            print(\"[HW] USB Camera Released.\")\n",
    "            \n",
    "        robot.stop()\n",
    "        self.reset_servos()\n",
    "\n",
    "agv_hw = AgvHardware()\n",
    "\n",
    "# =========================================================\n",
    "# 3. Ìó¨Ìçº Ìï®Ïàò\n",
    "# =========================================================\n",
    "def flush_camera(n=5):\n",
    "    for _ in range(n):\n",
    "        _ = camera.value\n",
    "        time.sleep(0.01)\n",
    "\n",
    "def smart_turn_180(direction=\"left\"):\n",
    "    print(\"[TURN] Smart 180 started...\")\n",
    "    BLIND_SEC = 4.5; BLIND_POWER = 0.4\n",
    "    if direction == \"left\":\n",
    "        robot.left_motor.value  = -BLIND_POWER; robot.right_motor.value = +BLIND_POWER\n",
    "    else:\n",
    "        robot.left_motor.value  = +BLIND_POWER; robot.right_motor.value = -BLIND_POWER\n",
    "    time.sleep(BLIND_SEC)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    SEARCH_POWER = 0.15\n",
    "    if direction == \"left\":\n",
    "        robot.left_motor.value  = -SEARCH_POWER; robot.right_motor.value = +SEARCH_POWER\n",
    "    else:\n",
    "        robot.left_motor.value  = +SEARCH_POWER; robot.right_motor.value = -SEARCH_POWER\n",
    "    while time.time() - t0 < 5.0:\n",
    "        frame = camera.value\n",
    "        if frame is None: time.sleep(0.01); continue\n",
    "        out = model(preprocess(frame))\n",
    "        xy = out.detach().float().cpu().numpy().flatten()\n",
    "        if abs(xy[0]) < 0.25: break\n",
    "        time.sleep(0.01)\n",
    "    robot.stop(); flush_camera(10)\n",
    "\n",
    "# =========================================================\n",
    "# 4. ÏûëÏóÖ Î∂ÑÎ∞∞Í∏∞\n",
    "# =========================================================\n",
    "def execute_work_logic(task_type, location):\n",
    "    print(f\"‚öôÔ∏è [WORK] Executing '{task_type}' at '{location}'...\")\n",
    "    try:\n",
    "        if task_type == \"deliver_water\":\n",
    "            if location == \"WATER\": agv_hw.align_and_pick('cup') \n",
    "            elif location.startswith(\"RES_\"): agv_hw._place_cup_motion()\n",
    "        elif task_type == \"collect_cup\":\n",
    "            if location.startswith(\"RES_\"): agv_hw.align_and_pick('cup')\n",
    "            elif location == \"WATER\": agv_hw._place_cup_motion()\n",
    "        elif task_type == \"collect_laundry\":\n",
    "            if location.startswith(\"RES_\"): agv_hw.align_and_pick('laundry')\n",
    "            elif location == \"DROP\": agv_hw._place_block()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è [WORK] Error: {e}\")\n",
    "        agv_hw.reset_servos()\n",
    "    print(f\"‚öôÔ∏è [WORK] Finished.\")\n",
    "\n",
    "# =========================================================\n",
    "# 5. Task Start\n",
    "# =========================================================\n",
    "def start_task(task_id, task_type, target_area_input):\n",
    "    global line_follow_enabled, state, current_task_id, current_task_type\n",
    "    global current_waypoints, target_idx, track_dir, target_area, angle_last, _last_log_t, force_arrival\n",
    "\n",
    "    tgt_nm = str(target_area_input or \"RES_B\").upper().strip()\n",
    "    typ = str(task_type or \"unknown\").lower().strip()\n",
    "    current_task_type = typ \n",
    "\n",
    "    wps = []\n",
    "    if typ == \"deliver_water\": wps = [\"WATER\", tgt_nm, \"CHARGE\"]\n",
    "    elif typ == \"collect_cup\": wps = [tgt_nm, \"WATER\", \"CHARGE\"]\n",
    "    elif typ == \"collect_laundry\": wps = [tgt_nm, \"DROP\", \"CHARGE\"]\n",
    "    else: wps = [tgt_nm]\n",
    "\n",
    "    valid_wps = [w for w in wps if w in AREA_TO_IDX]\n",
    "    if not valid_wps: print(f\"[TASK] Invalid wps: {wps}\"); return\n",
    "\n",
    "    with _lock:\n",
    "        if line_follow_enabled: return\n",
    "        first_dest = valid_wps.pop(0)\n",
    "        tgt_idx = int(AREA_TO_IDX[first_dest])\n",
    "        with track_lock: cur_idx = int(track_idx_f)\n",
    "        current_waypoints = valid_wps\n",
    "        desired_dir = choose_shortest_dir(cur_idx, tgt_idx)\n",
    "        if desired_dir != track_dir:\n",
    "            print(f\"[TURN] Init Smart 180\"); smart_turn_180(\"left\")\n",
    "            track_dir = desired_dir\n",
    "        with state_lock:\n",
    "            state = \"running\"; current_task_id = task_id\n",
    "            target_area = first_dest; target_idx = tgt_idx\n",
    "        angle_last = 0.0; _last_log_t = 0.0\n",
    "        flush_camera(10)\n",
    "        line_follow_enabled = True\n",
    "    print(f\"[TASK] START {typ} -> wps={wps}\")\n",
    "\n",
    "def stop_line_follow():\n",
    "    global line_follow_enabled\n",
    "    with _lock: line_follow_enabled = False\n",
    "    try: robot.stop()\n",
    "    except: pass\n",
    "    print(\"[LINE] Force STOP.\")\n",
    "\n",
    "# =========================================================\n",
    "# 6. Î©îÏù∏ Î£®ÌîÑ (DONE ÏàòÏ†ïÎê®)\n",
    "# =========================================================\n",
    "def _line_loop():\n",
    "    global line_follow_enabled, state, done_until, target_area, target_idx, track_dir\n",
    "    global current_waypoints, angle_last, _last_log_t, force_arrival\n",
    "\n",
    "    print(\"[LOOP] Step 4 Final (Resource Optimized).\")\n",
    "    arrive_t0 = None\n",
    "    \n",
    "    _SPEED = globals().get('SPEED', 0.30)\n",
    "    _GAIN = globals().get('STEERING_GAIN', 0.20)\n",
    "    _DGAIN = globals().get('STEERING_DGAIN', 0.05)\n",
    "    _BIAS = globals().get('STEERING_BIAS', 0.00)\n",
    "    _DT = globals().get('LINE_LOOP_DT', 0.02)\n",
    "\n",
    "    try:\n",
    "        while not line_stop.is_set():\n",
    "            with _lock: enabled = line_follow_enabled\n",
    "            if not enabled:\n",
    "                update_track_progress_if_running(False, False)\n",
    "                time.sleep(0.02); continue\n",
    "\n",
    "            # 1. ÎèÑÏ∞© ÌåêÏ†ï\n",
    "            is_arrived = False; dist_ok = False\n",
    "            if state == \"running\" and target_idx is not None:\n",
    "                with track_lock: cur_i = int(track_idx_f) % globals().get('TRACK_N', 800)\n",
    "                d = ring_dist(cur_i, int(target_idx))\n",
    "                if d <= _ARRIVE_IDX_TOL: dist_ok = True\n",
    "            \n",
    "            if force_arrival:\n",
    "                is_arrived = True; force_arrival = False\n",
    "            elif dist_ok:\n",
    "                if arrive_t0 is None: arrive_t0 = time.monotonic()\n",
    "                elif time.monotonic() - arrive_t0 >= _ARRIVE_HOLD_SEC: is_arrived = True\n",
    "            else: arrive_t0 = None\n",
    "            \n",
    "            # 2. ÎèÑÏ∞© Ïãú\n",
    "            if is_arrived:\n",
    "                robot.stop(); time.sleep(0.15)\n",
    "                snap_track_idx(int(target_idx))\n",
    "                curr_dest_name = target_area\n",
    "                print(f\"[ARRIVE] Reached {curr_dest_name}\")\n",
    "                arrive_t0 = None\n",
    "\n",
    "                with state_lock: state = \"working\"\n",
    "                execute_work_logic(current_task_type, curr_dest_name)\n",
    "                flush_camera(10) # ‚òÖ‚òÖ‚òÖ Ïó¨Í∏∞ÏÑú CSI Ïπ¥Î©îÎùº Î≤ÑÌçº ÏôïÏ∞Ω ÎπÑÏõÄ (Ï§ëÏöî) ‚òÖ‚òÖ‚òÖ\n",
    "\n",
    "                if len(current_waypoints) > 0:\n",
    "                    next_dest = current_waypoints.pop(0)\n",
    "                    next_idx = int(AREA_TO_IDX[next_dest])\n",
    "                    cur_i = int(target_idx)\n",
    "                    desired = choose_shortest_dir(cur_i, next_idx)\n",
    "                    if desired != track_dir:\n",
    "                        print(f\"[TURN] 180\"); smart_turn_180(\"left\")\n",
    "                        track_dir = desired; angle_last = 0.0\n",
    "                        flush_camera(10)\n",
    "                    with state_lock:\n",
    "                        state = \"running\"; target_area = next_dest; target_idx = next_idx\n",
    "                    print(f\"[NEXT] Heading to {next_dest}\")\n",
    "                    continue \n",
    "                else:\n",
    "                    with state_lock:\n",
    "                        state = \"done\"\n",
    "                        target_area = None\n",
    "                        done_until = time.monotonic() + _DONE_HOLD_SEC\n",
    "                    with _lock: line_follow_enabled = False\n",
    "                    print(\"[DONE] All tasks finished.\")\n",
    "                    continue\n",
    "\n",
    "            # 3. Ï£ºÌñâ\n",
    "            frame = camera.value\n",
    "            if frame is None: \n",
    "                update_track_progress_if_running(state==\"running\", False)\n",
    "                time.sleep(0.02); continue\n",
    "\n",
    "            try:\n",
    "                out = model(preprocess(frame))\n",
    "                xy = out.detach().float().cpu().numpy().flatten()\n",
    "                x = float(xy[0]); y = float((0.5 - xy[1]) / 2.0)\n",
    "                angle = float(np.arctan2(x, y))\n",
    "                pid = angle * _GAIN + (angle - angle_last) * _DGAIN\n",
    "                angle_last = angle\n",
    "                steering = pid + _BIAS\n",
    "                left  = float(np.clip(_SPEED + steering, 0.0, 1.0))\n",
    "                right = float(np.clip(_SPEED - steering, 0.0, 1.0))\n",
    "                \n",
    "                robot.left_motor.value = left; robot.right_motor.value = right\n",
    "                update_track_progress_if_running(state==\"running\", True)\n",
    "                \n",
    "                now = time.time()\n",
    "                if _PRINT_MOTOR and (now - _last_log_t >= _LOG_EVERY_SEC):\n",
    "                    _last_log_t = now\n",
    "                    print(f\"[RUN] x={x:+.2f} L={left:.2f} R={right:.2f} tgt={target_area}\")\n",
    "            except Exception as e:\n",
    "                robot.stop(); time.sleep(0.1)\n",
    "            time.sleep(_DT)\n",
    "\n",
    "    finally:\n",
    "        try: robot.stop()\n",
    "        except: pass\n",
    "        print(\"[LOOP] Line loop stopped.\")\n",
    "\n",
    "if 'line_thread' in globals() and line_thread.is_alive():\n",
    "    line_stop.set(); line_thread.join()\n",
    "\n",
    "line_stop.clear()\n",
    "line_thread = threading.Thread(target=_line_loop, daemon=True)\n",
    "line_thread.start()\n",
    "print(\"[OK] Step4 Final RESTARTED (Resource Optimized)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "according-continent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQTT] connecting to 10.41.145.221:1883 ...\n",
      "[PUB] status publisher started\n",
      "[MQTT] connected & subscribed (robot/agv1/task, robot/agv1/dev)\n",
      "[TASK] START collect_laundry -> wps=['RES_A', 'DROP', 'CHARGE']\n",
      "[RUN] x=-0.09 L=0.02 R=0.58 tgt=RES_A\n",
      "[RUN] x=-0.02 L=0.26 R=0.34 tgt=RES_A\n",
      "[RUN] x=-0.03 L=0.24 R=0.36 tgt=RES_A\n",
      "[RUN] x=-0.05 L=0.22 R=0.38 tgt=RES_A\n",
      "[RUN] x=-0.09 L=0.15 R=0.45 tgt=RES_A\n",
      "[RUN] x=-0.23 L=0.08 R=0.52 tgt=RES_A\n",
      "[RUN] x=-0.07 L=0.15 R=0.45 tgt=RES_A\n",
      "[RUN] x=-0.10 L=0.04 R=0.56 tgt=RES_A\n",
      "[RUN] x=-0.05 L=0.10 R=0.50 tgt=RES_A\n",
      "[RUN] x=+0.00 L=0.34 R=0.26 tgt=RES_A\n",
      "[RUN] x=+0.09 L=0.51 R=0.09 tgt=RES_A\n",
      "[RUN] x=-0.04 L=0.19 R=0.41 tgt=RES_A\n",
      "[RUN] x=-0.06 L=0.14 R=0.46 tgt=RES_A\n",
      "[RUN] x=-0.00 L=0.30 R=0.30 tgt=RES_A\n",
      "[RUN] x=-0.02 L=0.27 R=0.33 tgt=RES_A\n",
      "[RUN] x=-0.02 L=0.26 R=0.34 tgt=RES_A\n",
      "[RUN] x=-0.05 L=0.18 R=0.42 tgt=RES_A\n",
      "[RUN] x=-0.02 L=0.22 R=0.38 tgt=RES_A\n",
      "[RUN] x=-0.04 L=0.18 R=0.42 tgt=RES_A\n",
      "[ARRIVE] Reached RES_A\n",
      "‚öôÔ∏è [WORK] Executing 'collect_laundry' at 'RES_A'...\n",
      "[HW] Opening USB Camera...\n",
      "üëÄ [ALIGN] Searching for 'doll'...\n",
      "..... FOUND! ('doll', 0.8965510627031676, [-10, 1, 1140, 647])\n",
      " FOUND! ('doll', 0.9476145329331302, [431, 0, 1915, 528])\n",
      " FOUND! ('doll', 0.8960169159448128, [446, -1, 1902, 465])\n",
      " FOUND! ('doll', 0.794230611448981, [454, -2, 1902, 473])\n",
      " FOUND! ('doll', 0.899141408955586, [453, -2, 1898, 491])\n",
      " FOUND! ('doll', 0.9002507303867873, [439, -4, 1896, 516])\n",
      " FOUND! ('doll', 0.8984222189215316, [444, -4, 1890, 510])\n",
      " FOUND! ('doll', 0.9252288664242769, [432, -4, 1903, 536])\n",
      " FOUND! ('doll', 0.9118695137958177, [427, -4, 1904, 542])\n",
      " FOUND! ('doll', 0.8771918952364643, [430, -3, 1902, 540])\n",
      " FOUND! ('doll', 0.8475322277525166, [433, -4, 1908, 579])\n",
      " FOUND! ('doll', 0.8207584403809918, [435, -3, 1912, 586])\n",
      " FOUND! ('doll', 0.8847359449983543, [438, -3, 1909, 605])\n",
      " FOUND! ('doll', 0.8710505791065657, [429, -3, 1904, 621])\n",
      " FOUND! ('doll', 0.8788703802367692, [439, -2, 1911, 645])\n",
      " FOUND! ('doll', 0.8624695871987598, [442, -1, 1908, 657])\n",
      " FOUND! ('doll', 0.8597737846599784, [441, -1, 1900, 692])\n",
      " FOUND! ('doll', 0.8897479434914395, [440, -3, 1905, 709])\n",
      " FOUND! ('doll', 0.8739365345436454, [426, -2, 1901, 719])\n",
      " FOUND! ('doll', 0.8918193780272645, [431, -4, 1905, 747])\n",
      " FOUND! ('doll', 0.8884213451304319, [421, -2, 1899, 742])\n",
      " FOUND! ('doll', 0.8991153972266908, [409, -2, 1901, 735])\n",
      " FOUND! ('doll', 0.899730538522391, [407, -4, 1903, 766])\n",
      " FOUND! ('doll', 0.8832415424203148, [403, -6, 1902, 795])\n",
      " FOUND! ('doll', 0.8561799159939056, [401, -5, 1901, 815])\n",
      " FOUND! ('doll', 0.8842338785483079, [379, -10, 1910, 830])\n",
      " FOUND! ('doll', 0.841861183624566, [399, -3, 1897, 853])\n",
      " FOUND! ('doll', 0.8760883183065147, [383, -5, 1899, 882])\n",
      " FOUND! ('doll', 0.8315295305096697, [379, -3, 1894, 866])\n",
      " FOUND! ('doll', 0.9139612829388852, [386, -10, 1885, 1009])\n",
      " FOUND! ('doll', 0.9184446612752666, [393, -7, 1884, 1028])\n",
      " FOUND! ('doll', 0.9561120475061529, [382, -7, 1895, 1041])\n",
      " FOUND! ('doll', 0.9553753602967774, [364, -1, 1894, 1031])\n",
      " FOUND! ('doll', 0.9557745842868925, [343, 0, 1895, 1028])\n",
      " FOUND! ('doll', 0.9415735674832675, [351, 2, 1897, 1030])\n",
      " FOUND! ('doll', 0.9440305879946322, [340, 4, 1893, 1044])\n",
      " FOUND! ('doll', 0.9399553560082552, [330, 3, 1896, 1042])\n",
      " FOUND! ('doll', 0.9367732899948038, [323, 4, 1889, 1042])\n",
      " FOUND! ('doll', 0.9547369814976037, [319, 2, 1892, 1065])\n",
      " FOUND! ('doll', 0.9515813137989149, [309, 6, 1887, 1057])\n",
      " FOUND! ('doll', 0.9528300764954167, [289, 7, 1885, 1062])\n",
      " FOUND! ('doll', 0.9484992453167109, [267, 8, 1888, 1060])\n",
      " FOUND! ('doll', 0.9478471909624631, [260, 7, 1886, 1064])\n",
      "\n",
      "‚úÖ [ALIGN] Y-Align Done.\n",
      " FOUND! ('doll', 0.92548596298532, [194, 2, 1881, 1070])\n",
      " FOUND! ('doll', 0.9159483106276411, [189, 3, 1880, 1068])\n",
      " FOUND! ('doll', 0.9428594132964463, [63, -8, 1912, 1083])\n",
      " FOUND! ('doll', 0.956942262901066, [5, -2, 1850, 1082])\n",
      " FOUND! ('doll', 0.9515025174356282, [2, 0, 1832, 1084])\n",
      " FOUND! ('doll', 0.9585671911477078, [2, 2, 1832, 1082])\n",
      " FOUND! ('doll', 0.9586898561110289, [3, -1, 1843, 1083])\n",
      " FOUND! ('doll', 0.9395501403876949, [42, 0, 1890, 1069])\n",
      " FOUND! ('doll', 0.9331290718178735, [79, -2, 1907, 1072])\n",
      " FOUND! ('doll', 0.9391933365620204, [82, -2, 1908, 1071])\n",
      " FOUND! ('doll', 0.9529373222364796, [83, -3, 1916, 1079])\n",
      " FOUND! ('doll', 0.9503414963944152, [47, 0, 1901, 1071])\n",
      " FOUND! ('doll', 0.9639718725407107, [0, -1, 1884, 1081])\n",
      " FOUND! ('doll', 0.9594722969219447, [0, 0, 1865, 1081])\n",
      " FOUND! ('doll', 0.9616971292949472, [-2, 0, 1862, 1079])\n",
      " FOUND! ('doll', 0.9637512642349364, [-5, -1, 1869, 1083])\n",
      " FOUND! ('doll', 0.9575318747888062, [23, 0, 1899, 1072])\n",
      "üéØ [ALIGN] X-Align Done. PICKING!\n",
      "ü¶æ [HW] Picking Laundry...\n"
     ]
    }
   ],
   "source": [
    "mqtt_connected = threading.Event()\n",
    "TOPIC_DEV = \"robot/agv1/dev\"\n",
    "\n",
    "def on_connect(c, userdata, flags, rc, properties=None):\n",
    "    if rc == 0:\n",
    "        c.subscribe(TOPIC_TASK, qos=0)\n",
    "        c.subscribe(TOPIC_DEV, qos=0)\n",
    "        print(f\"[MQTT] connected & subscribed ({TOPIC_TASK}, {TOPIC_DEV})\")\n",
    "        mqtt_connected.set()\n",
    "\n",
    "def on_message(c, userdata, msg):\n",
    "    try:\n",
    "        text = msg.payload.decode(\"utf-8\", errors=\"ignore\").strip()\n",
    "        obj = json.loads(text) if text else {}\n",
    "    except:\n",
    "        return\n",
    "\n",
    "    # 1. Dev/Cheat Î™ÖÎ†π\n",
    "    if msg.topic == TOPIC_DEV:\n",
    "        cmd = str(obj.get(\"cmd\") or \"\").lower()\n",
    "        if cmd == \"fix_pose\":\n",
    "            area_key = str(obj.get(\"area\") or \"\").upper()\n",
    "            if area_key in AREA_TO_IDX:\n",
    "                new_idx = int(AREA_TO_IDX[area_key])\n",
    "                snap_track_idx(new_idx)\n",
    "                print(f\"[CHEAT] Force position sync to {area_key} (idx={new_idx})\")\n",
    "                \n",
    "                with state_lock:\n",
    "                    global area, target_area, force_arrival, state\n",
    "                    area = area_key\n",
    "                    if state == \"running\" and target_area == area_key:\n",
    "                        force_arrival = True\n",
    "                        print(f\"[CHEAT] Target matched! Force Stopping...\")\n",
    "            else:\n",
    "                print(f\"[CHEAT] Unknown area code: {area_key}\")\n",
    "        return\n",
    "\n",
    "    # 2. ÏùºÎ∞ò Task\n",
    "    if isinstance(obj, dict):\n",
    "        cmd = str(obj.get(\"cmd\") or obj.get(\"action\") or \"\").lower().strip()\n",
    "        if cmd in (\"stop\", \"off\", \"cancel\", \"idle\", \"done\"):\n",
    "            stop_line_follow()\n",
    "            return\n",
    "\n",
    "    task_id = obj.get(\"task_id\") or obj.get(\"id\") or f\"t_{int(time.time())}\"\n",
    "    task_type = obj.get(\"type\") or \"unknown\"\n",
    "    target_area = obj.get(\"target_area\") or obj.get(\"target\")\n",
    "\n",
    "    start_task(task_id, task_type, target_area)\n",
    "\n",
    "# Í∏∞Ï°¥ ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï†ïÎ¶¨\n",
    "if 'client' in globals():\n",
    "    try: client.loop_stop(); client.disconnect()\n",
    "    except: pass\n",
    "\n",
    "client = mqtt.Client(client_id=CLIENT_ID)\n",
    "client.on_connect = on_connect\n",
    "client.on_message = on_message\n",
    "client.reconnect_delay_set(min_delay=1, max_delay=5)\n",
    "\n",
    "print(f\"[MQTT] connecting to {BROKER_IP}:{BROKER_PORT} ...\")\n",
    "client.connect(BROKER_IP, BROKER_PORT, keepalive=60)\n",
    "client.loop_start()\n",
    "\n",
    "# ===== [Ìï®Ïàò Ï∂îÍ∞Ä] CPU Ïò®ÎèÑ ÏùΩÍ∏∞ =====\n",
    "def get_cpu_temp():\n",
    "    try:\n",
    "        with open(\"/sys/devices/virtual/thermal/thermal_zone0/temp\", \"r\") as f:\n",
    "            return round(float(f.read().strip()) / 1000.0, 1)\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "# ===== [Ìï®Ïàò Ï∂îÍ∞Ä] Î∞∞ÌÑ∞Î¶¨ ÏùΩÍ∏∞ (ÌåÄÏõê ÏΩîÎìú Î°úÏßÅ Ï†ÅÏö©) =====\n",
    "def get_battery_pct():\n",
    "    if not ina: return 0\n",
    "    try:\n",
    "        v = ina.getBusVoltage_V()\n",
    "        # ÌåÄÏõê Í≥µÏãù: (Ï†ÑÏïï / 12.6V) * 100\n",
    "        pct = (v / 12.6) * 100\n",
    "        return int(max(0, min(100, pct))) # 0~100 ÏÇ¨Ïù¥Î°ú ÏïàÏ†ÑÌïòÍ≤å ÏûêÎ¶Ñ\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def _status_loop():\n",
    "    global state, current_task_id \n",
    "    print(\"[PUB] status publisher started\")\n",
    "    while True:\n",
    "        mqtt_connected.wait()\n",
    "        with state_lock:\n",
    "            if state == \"done\" and time.monotonic() >= done_until:\n",
    "                state = \"idle\"\n",
    "                current_task_id = None\n",
    "            st = state\n",
    "            tid = current_task_id\n",
    "            ar = area\n",
    "            tar = target_area\n",
    "\n",
    "        pose, dbg = get_track_pose()\n",
    "        \n",
    "        # [ÌïµÏã¨] Ïã§Ï†ú Í∞í ÏùΩÏñ¥Ïò§Í∏∞\n",
    "        real_cpu = get_cpu_temp()\n",
    "        real_bat = get_battery_pct()\n",
    "        \n",
    "        # global battery Î≥ÄÏàò ÏóÖÎç∞Ïù¥Ìä∏ (ÌòπÏãú Îã§Î•∏Îç∞ÏÑú Ïì∏ÍπåÎ¥ê)\n",
    "        global battery\n",
    "        battery = real_bat\n",
    "\n",
    "        payload = {\n",
    "            \"robot_id\": robot_id,\n",
    "            \"state\": st,\n",
    "            \"task_id\": tid,\n",
    "            \"battery\": real_bat,  # ÏßÑÏßú Î∞∞ÌÑ∞Î¶¨\n",
    "            \"cpu_temp\": real_cpu, # ÏßÑÏßú Ïò®ÎèÑ\n",
    "            \"area\": ar,\n",
    "            \"target_area\": tar,\n",
    "            \"pose\": pose,\n",
    "            \"updated_at\": int(time.time() * 1000),\n",
    "            \"_debug\": dbg,\n",
    "        }\n",
    "        try: client.publish(TOPIC_STATUS, json.dumps(payload), qos=0)\n",
    "        except: pass\n",
    "        time.sleep(STATUS_PERIOD_SEC)\n",
    "\n",
    "if '_status_thread' not in globals() or not _status_thread.is_alive():\n",
    "    _status_thread = threading.Thread(target=_status_loop, daemon=True)\n",
    "    _status_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shutdown():\n",
    "    stop_line_follow()\n",
    "    try: line_stop.set()\n",
    "    except: pass\n",
    "    time.sleep(0.1)\n",
    "    try:\n",
    "        client.loop_stop()\n",
    "        client.disconnect()\n",
    "    except: pass\n",
    "    try: robot.stop()\n",
    "    except: pass\n",
    "    try: camera.stop()\n",
    "    except: pass\n",
    "    print(\"[DONE] shutdown\")\n",
    "\n",
    "# ÌïÑÏöîÌï† ÎïåÎßå Ï£ºÏÑù ÌíÄÍ≥† Ïã§ÌñâÌïòÏÑ∏Ïöî\n",
    "shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-pressing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
